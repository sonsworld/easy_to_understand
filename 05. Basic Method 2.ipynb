{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='img/fastcamp_h.png'>\n",
    "\n",
    "# 5강. Deep Learning from Basic Method 2 with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# AI의 겨울\n",
    "\n",
    "* perceptron이 이렇게 강력했지만 이후 ai는 20년에 가까운 시간 동안 \"AI Winter\"라는 시기를 겪음\n",
    "* 왜 그럴까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# XOR PROBLEM; 비선형 문제\n",
    "\n",
    "<img src='img/05_01.png' width=30% height=30%>\n",
    "\n",
    "* 기존의 AND 문제, OR 문제는 방정식 1개로 (선형으로) 문제를 해결 할 수 있었음\n",
    "* 그러나 XOR는 1개의 방정식으로 해결 할 수 없음\n",
    "  * 이 문제를 perceptron은 절대 해결 할 수 없기 때문에 AI winter가 찾아옴\n",
    "  * 1969년 Marvin Minsky와 Seymour Papert의 “Perceptrons: an introduction to computational geometry”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multi-Layer Perceptron(MLP) 의 등장\n",
    "\n",
    "* 1986년 McClelland, James L., David E. Rumelhart, and **Geoffrey E. Hinton**이 MLP를 발표\n",
    "* 이전 perceptron의 출력을 또다른 perceptron의 입력으로 사용하고 현재 출력에 비선형 step function을 사용하여 MLP가 비선형으로 동작하게 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# 선형 분류와 비선형 분류의 차이\n",
    "\n",
    "<center><img src='img/05_03.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 다시보는 Perceptron의 구조\n",
    "\n",
    "<center><img src='img/03_01.png'></center>\n",
    "\n",
    "* input($x_n$): 외부에서 들어오는 입력, 보통 vector, matrix\n",
    "* weight($w_n$): x와 곱해지는 가중치, DL에서 구해야하는 값\n",
    "* bias($1$): 바이어스, 절편 값\n",
    "* sigma: x와 w의 곱 + bias의 합을 출력\n",
    "* step function: 해당 출력의 활성 여부를 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multi-Layer Perceptron의 구조\n",
    "\n",
    "<center><img src='img/05_02.png' height=50% width=50%></center>\n",
    "\n",
    "* input layer: 외부에서 들어오는 입력, 보통 vector, matrix\n",
    "* hidden layer:\n",
    " 1. 각 노드는 이전 layer의 출력을 입력으로 받음\n",
    " 2. hidden layer의 각 노드는 step funtion을 가짐\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multi-Layer Perceptron의 구조\n",
    "\n",
    "<center><img src='img/05_02.png' height=50% width=50%></center>\n",
    "\n",
    "* hidden layer의 각 노드\n",
    " * weight($w_n$): 이전 입력과 곱해지는 가중치, DL에서 구해야하는 값\n",
    " * bias($1$): 바이어스, 절편 값\n",
    " * sigma: 입력과 w의 곱 + bias의 합을 출력\n",
    " * activation/step function: 해당 출력의 활성 여부를 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# XOR GATE model의 구조\n",
    "<br><br>\n",
    "<center><img src='img/05_04.png' width=70% height=70%></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차: 1.1934709548950195\n",
      "오차: 0.1989368498325348\n",
      "오차: 0.15673863887786865\n",
      "오차: 0.12096760421991348\n",
      "오차: 0.0845719426870346\n",
      "오차: 0.05304841324687004\n",
      "오차: 0.02948678657412529\n",
      "오차: 0.014505070634186268\n",
      "오차: 0.0064311884343624115\n",
      "오차: 0.002637288300320506\n",
      "정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "#XOR 문제를 풀어보자\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_shape=(2,), activation='tanh'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = np.array([[0], [1], [1], [0]])\n",
    "hist = model.fit(X, Y, epochs=3000, verbose=0)\n",
    "\n",
    "H = (model.predict(X) > 0.5).astype(np.float32)\n",
    "for loss in hist.history['loss'][::300]:\n",
    "    print('오차:', loss)\n",
    "print('정확도:', np.mean(np.equal(H, Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Activation을 선형으로 바꾸면 어떻게 될까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차: 1.3322943449020386\n",
      "오차: 0.25137215852737427\n",
      "오차: 0.2500744163990021\n",
      "오차: 0.25000476837158203\n",
      "오차: 0.2500002980232239\n",
      "오차: 0.2500000298023224\n",
      "오차: 0.25\n",
      "오차: 0.25\n",
      "오차: 0.2499999701976776\n",
      "오차: 0.25\n",
      "정확도: 0.75\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_shape=(2,), activation='linear'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = np.array([[0], [1], [1], [0]])\n",
    "hist = model.fit(X, Y, epochs=3000, verbose=0)\n",
    "\n",
    "H = (model.predict(X) > 0.5).astype(np.float32)\n",
    "for loss in hist.history['loss'][::300]:\n",
    "    print('오차:', loss)\n",
    "print('정확도:', np.mean(np.equal(H, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차: 0.9149474501609802\n",
      "오차: 0.25\n",
      "오차: 0.25\n",
      "오차: 0.25\n",
      "오차: 0.25\n",
      "오차: 0.25\n",
      "오차: 0.25\n",
      "오차: 0.25\n",
      "오차: 0.25\n",
      "오차: 0.25\n",
      "정확도: 0.25\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_shape=(2,), activation='linear'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = np.array([[0], [1], [1], [0]])\n",
    "hist = model.fit(X, Y, epochs=30000, verbose=0)           #epochs가 부족해서 그런건 아닐까? 3만번 돌려보\n",
    "\n",
    "H = (model.predict(X) > 0.5).astype(np.float32)\n",
    "for loss in hist.history['loss'][::3000]:\n",
    "    print('오차:', loss)\n",
    "print('정확도:', np.mean(np.equal(H, Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 선형은 아무리 겹쳐도 선형\n",
    "\n",
    "* XOR MLP의 수식을 다음과 같다고 가정\n",
    "\n",
    "\\begin{align}\n",
    "g(f(x)) = y \\nonumber\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "f(x) = ax + b \\nonumber \\\\\n",
    "g(x) = cx + d \\nonumber \\\\\n",
    "z(x) = mx + n \\nonumber\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "g(f(x)) &= y \\nonumber \\\\\n",
    "&= c(ax + b) + d \\nonumber \\\\\n",
    "&= cax + cb + d \\nonumber \\\\\n",
    "&= (ca)x + (cb + d), ca \\rightarrow m, cb + d \\rightarrow n  \\nonumber \\\\\n",
    "&= mx + n \\nonumber \\\\\n",
    "&= z(x) \\nonumber\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 왜 이렇게 오래걸렸나?\n",
    "\n",
    "* 우리가 보기에 바뀐게 거의 없을 정도\n",
    "* 그런데 왜 20여년 정도 AI winter였을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Loss Function의 어려움\n",
    "\n",
    "* Marvin Minsky 교수는 MLP와 같은 개념으로 XOR를 풀 수 있다는 것은 알고 있었음\n",
    "* 그러나 MLP 같은 방식의 모델에서 loss/cost function을 수행하는 것이 불가능하다고 단정\n",
    "\n",
    "<center><img src='img/03_05.png' width=50% height=50%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 5~6년 뒤 MIT 박사과정의 Paul werbos가 backpropagation를 통한 학습이 가능함을 연구하였지만 당시 분위기상 무시됨\n",
    "* 그것을 박사과정 중이던 르쿤 교수가 다시 찾아내고(1984), 2년 뒤 힌튼 교수가 백프로퍼게이션을 재정립(1986) 시키면서 MLP가 부활함\n",
    "\n",
    "<center><img src='img/05_04.png' width=100% height=100%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backpropagation (역전파)\n",
    "\n",
    "* chain-rule을 이용하는 그라디언트 디센트 방식\n",
    "* ANN을 효율적으로 학습하기 위하여 가중치 업데이트를 반복/재귀적으로 역순 수행함\n",
    "* activation의 결과를 어떻게 미분할지 설정해야함\n",
    " * 최근 많은 라이브러리에서 Automatic differentiation를 제공하여 사용자가 function에 대한 미분을 정의할 필요는 없음\n",
    "* 일반적으로 그라디언트 디센트를 통하여 loss function의 기울기를 계산하여 가중치를 조절함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backprop의 concept\n",
    "\n",
    "## Gradient Descent\n",
    "\n",
    "* 함수를 미분하여 오차가 감소하는 방향으로 $\\alpha$만큼 기울기를 조절\n",
    "\n",
    "## Chain-rule을 이용한 computation graph\n",
    "\n",
    "* 계산 연산을 그래프 구조 형태로 변환하여 복잡한 미분을 쉽게 분해하여 단계별로 하는 기법\n",
    "* 즉, computation graph를 이용하여 복잡한 수식을 미분 입장에서 쉽게 변경한 뒤 각각을 미분하여 GD방법으로 오차를 줄임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$ f(x,y,z) = (x+y)z \\nonumber $$\n",
    "\n",
    "$$ x = -2 \\nonumber $$\n",
    "$$ y = 5 \\nonumber $$\n",
    "$$ z = -4 \\nonumber $$\n",
    "\n",
    "<center><img src='img/05_08.png' width=25% height=25%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* chain-rule을 적용하기 위해 다음과 같이 치환 가능\n",
    "\n",
    "$$ f(x,y,z) = g(h(x,y),z) \\nonumber $$\n",
    "$$ h(x,y) = x + y, g(a,b) = a * b \\nonumber $$\n",
    "\n",
    "$$ \\frac{df}{dx} =  \\frac{dg}{dh}\\frac{dh}{dx} \\nonumber $$\n",
    "\n",
    "$$ \\frac{df}{dy} =  \\frac{dg}{dh}\\frac{dh}{dy} \\nonumber $$\n",
    "\n",
    "$$ q = x + y, \\frac{dq}{dx} = 1,  \\frac{dq}{dy} = 1 \\nonumber $$\n",
    "\n",
    "$$ f = qz, \\frac{df}{dq} = z, \\frac{df}{dz} = q \\nonumber $$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img/05_09.png' width=25% height=25%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src='img/05_10.png' width=25% height=25%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img/05_11.png' width=25% height=25%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src='img/05_12.png' width=25% height=25%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img/05_13.png' width=20% height=20%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src='img/05_14.png' width=20% height=20%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# computation graph의 핵심\n",
    "\n",
    "* 전역적 미분을 연산당 국소적 미분으로 변경함\n",
    "\n",
    "<center><img src='img/05_15.png' width=50% height=50%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* 모든 연산 입장에서는 들어오는 오차에 대해서만 미분하면 연쇄적으로 전체를 미분하는 효과\n",
    "<center><img src='img/05_16.png' width=50% height=50%></center>\n",
    "\n",
    "* https://slideplayer.com/slide/14389002/ 예제를 포함한 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 결과적으로 MLP의 연결은 다음과 같은 형태의 그래프로 표현 될 수 있음\n",
    "<center><img src='img/05_17.png' width=100% height=100%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 재귀적으로 미분을하여 뒤로 보냄 \n",
    "<center><img src='img/05_18.png' width=100% height=100%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 그래도 AI의 봄은 찾아오지 않았다..\n",
    "\n",
    "* 왜?\n",
    " * XOR 같은 비선형 문제를 MLP로 학습 할 수 있고\n",
    " * MLP의 loss를 개선함이 어려운 것도 backprop과 computation graph를 이용하여 해결했는데?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## 여기에는 2가지 이유가 있음\n",
    " 1. 그당시 MLP가 복잡한 것에 비하여 모델의 성능이 SVM(support vector machine)에 비하여 많이 떨어졌음\n",
    " 2. Layer가 깊어지면 깊어질수록 제대로 backprop으로 학습이 되지 않았음\n",
    " 3. 깊지 않은 layer에서도 계수가 폭발하면서 학습이 제대로 되지 않는 경우가 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# exploding gradient와 vanishing gradient\n",
    "\n",
    " * 자꾸 문제만 나오는 MLP는 언제 빛을 볼 수 있을것인가..\n",
    " \n",
    " * exploding gradient는 gd를 수행 중 계수 값이 음수나 양수 방향으로 폭발하여 inf이나 nan을 떨어뜨리는 문제\n",
    " * vanishing gradient는 gd를 수행 할 때 backprop시 전달 되는 값이 너무 작아 오차가 수정이 안되는 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# vanishing gradient\n",
    "\n",
    "* MLP의 비선형성을 위해 퍼셉트론의 출력에 비선형 activation 함수를 부여함\n",
    "* 당시에는 보통 tanh와 sigmoid를 주로 씀\n",
    "* tanh와 sigmoid 그래프는 다음과 같음\n",
    "\n",
    "<center><img src='img/04_04.png' width=50% height=50%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# vanishing gradient\n",
    "\n",
    "* 해당 함수는 미분했을 때 문제가 발생하게 됨\n",
    "* sigmoid와 tanh의 도함수 그래프는 다음과 같음\n",
    "\n",
    "<center><img src='img/05_19.png' width=50% height=50%></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[171.4031982421875,\n",
       " 1.1729990243911743,\n",
       " 0.3026695251464844,\n",
       " 0.0780981034040451,\n",
       " 0.0201517753303051,\n",
       " 0.005199815612286329,\n",
       " 0.0013417209265753627,\n",
       " 0.0003461816522758454,\n",
       " 8.932749187806621e-05,\n",
       " 2.3057200451148674e-05]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential([Dense(1, input_shape=(1,), activation='linear')]) #activation이 선형인 모델\n",
    "model.compile(loss='mse', optimizer=SGD(lr=0.01))\n",
    "\n",
    "X = np.array([1,2,3,4,5])\n",
    "Y = X * 3.6 + 6\n",
    "\n",
    "hist = model.fit(X, Y, epochs=2000, verbose=0)\n",
    "hist.history['loss'][::200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() #모델 구조에 대한 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.6015837]] [5.994282]\n"
     ]
    }
   ],
   "source": [
    "W, b = model.get_layer(index=0).get_weights()\n",
    "print(W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[315.59112548828125,\n",
       " 25.31235122680664,\n",
       " 10.003190994262695,\n",
       " 3.4869384765625,\n",
       " 2.197185754776001,\n",
       " 1.7836532592773438,\n",
       " 1.5377938747406006,\n",
       " 1.3311073780059814,\n",
       " 1.1565889120101929,\n",
       " 1.012955904006958]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([1,2,3,4,5])\n",
    "Y = X * 3.6 + 6\n",
    "\n",
    "#깊이가 3인 모델\n",
    "model = Sequential([Dense(1, input_shape=(1,), activation='sigmoid'), Dense(1, activation='sigmoid'), Dense(1, activation='linear')])\n",
    "model.compile(loss='mse', optimizer=SGD(lr=0.01))\n",
    "\n",
    "hist = model.fit(X, Y, epochs=2000, verbose=0)\n",
    "hist.history['loss'][::200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0560945]] [2.8487778]\n"
     ]
    }
   ],
   "source": [
    "W, b = model.get_layer(index=0).get_weights()\n",
    "print(W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#모델 구조에 대한 요약\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[324.3424987792969,\n",
       " 25.939754486083984,\n",
       " 25.93108558654785,\n",
       " 25.9239559173584,\n",
       " 25.91716957092285,\n",
       " 25.909704208374023,\n",
       " 25.900135040283203,\n",
       " 25.885562896728516,\n",
       " 25.858245849609375,\n",
       " 25.788105010986328]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#깊이가 4인 모델\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mse', optimizer=SGD(lr=0.01))\n",
    "\n",
    "X = np.array([1,2,3,4,5])\n",
    "Y = X * 3.6 + 6\n",
    "\n",
    "hist = model.fit(X, Y, epochs=2000, verbose=0)\n",
    "hist.history['loss'][::200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 20년 동안의 딥러닝의 겨울\n",
    "\n",
    "* 해당 문제는 20년 동안 고쳐지지 않음\n",
    "* 문제가 어려운 것도 있었으나, 여러번의 위기를 맞아 많은 연구자들이 떠남\n",
    "* 그리나 2006년 힌톤 교수가 새로운 activation과 학습 방법을 가지고 다시 찾아옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 힌톤 교수의 요약\n",
    "1. 우리는 학습셋을 너무 조금 써왔던 것이 아닐까?\n",
    "2. 우리의 컴퓨터가 너무 느렸던 것이 아닐까?\n",
    "3. 우리의 w초기화 방법이 잘못됐던 것이 아닐까?\n",
    "4. <b>우리는 잘못된 activation function을 써왔던 것이 아닐까?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#  Rectified Linear Unit: ReLU의 등장\n",
    "\n",
    "* $relu(x) = max(0, x)$의 아주 단순한 함수\n",
    "* 0 > x의 구간은 기울기가 0, 0 < x 의 구간은 기울기가 1이기 때문에 선형이 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "X = np.linspace(-10, 10, 100)\n",
    "plt.plot(X, relu(X))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차: 1.42637038230896\n",
      "오차: 0.07743463665246964\n",
      "오차: 0.011617137119174004\n",
      "오차: 0.0018648796249181032\n",
      "오차: 0.0002775207394734025\n",
      "오차: 3.9362617826554924e-05\n",
      "오차: 5.514316399057861e-06\n",
      "오차: 7.770465231260459e-07\n",
      "오차: 1.0769497293949826e-07\n",
      "오차: 1.5033709388490024e-08\n",
      "정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "#XOR 문제 by relu\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_shape=(2,), activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = np.array([[0], [1], [1], [0]])\n",
    "hist = model.fit(X, Y, epochs=3000, verbose=0)\n",
    "\n",
    "H = (model.predict(X) > 0.5).astype(np.float32)\n",
    "for loss in hist.history['loss'][::300]:\n",
    "    print('오차:', loss)\n",
    "print('정확도:', np.mean(np.equal(H, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[308.1600036621094,\n",
       " 26.00730323791504,\n",
       " 25.920024871826172,\n",
       " 25.919998168945312,\n",
       " 25.919998168945312,\n",
       " 25.919998168945312,\n",
       " 25.919998168945312,\n",
       " 25.919998168945312,\n",
       " 25.919998168945312,\n",
       " 25.919998168945312]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#깊이가 4인 모델\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mse', optimizer=SGD(lr=0.01))\n",
    "\n",
    "X = np.array([1,2,3,4,5])\n",
    "Y = X * 3.6 + 6\n",
    "\n",
    "hist = model.fit(X, Y, epochs=2000, verbose=0)\n",
    "hist.history['loss'][::200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.89397156]] [0.]\n",
      "[[-1.1320183]] [0.]\n",
      "[[-1.3468701]] [0.]\n",
      "[[-0.17741084]] [16.799953]\n"
     ]
    }
   ],
   "source": [
    "W, b = model.get_layer(index=0).get_weights()\n",
    "print(W, b)\n",
    "W, b = model.get_layer(index=1).get_weights()\n",
    "print(W, b)\n",
    "W, b = model.get_layer(index=2).get_weights()\n",
    "print(W, b)\n",
    "W, b = model.get_layer(index=3).get_weights()\n",
    "print(W, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# dying reLU problem!!!\n",
    "\n",
    "* relu는 입력값이 0 이하로 들어오면 activation 자체가 먹통이 됨\n",
    "* 출력을 0으로 주어로 비선형으로 동작하게 했지만 퍼셉트론이 많이 0이 되면 제대로 동작하지 않을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#아주 작은 기울기를 0 이하에 주어 죽지 않게 하자!\n",
    "def leaky_relu(x):\n",
    "    return np.where(x > 0, x, x * 0.01)\n",
    "\n",
    "X = np.linspace(-10, 10, 100)\n",
    "plt.plot(X, leaky_relu(X))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[307.1714782714844,\n",
       " 1.3407058077063994e-06,\n",
       " 1.6007107098148232e-11,\n",
       " 1.6007107098148232e-11,\n",
       " 1.6007107098148232e-11,\n",
       " 1.6007107098148232e-11,\n",
       " 1.6007107098148232e-11,\n",
       " 1.6007107098148232e-11,\n",
       " 1.6007107098148232e-11,\n",
       " 1.6007107098148232e-11]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#깊이가 4인 모델\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(1,), activation=tf.nn.leaky_relu)) #텐서플로우에 있는  leaky relu 이\n",
    "model.add(Dense(1, activation=tf.nn.leaky_relu))\n",
    "model.add(Dense(1, activation=tf.nn.leaky_relu))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mse', optimizer=SGD(lr=0.01))\n",
    "\n",
    "X = np.array([1,2,3,4,5])\n",
    "Y = X * 3.6 + 6\n",
    "\n",
    "hist = model.fit(X, Y, epochs=2000, verbose=0)\n",
    "hist.history['loss'][::200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.1125581]] [0.24710971]\n",
      "[[3.029983]] [0.09196756]\n",
      "[[-3.0472865]] [1.2211454]\n",
      "[[3.131636]] [2.6371586]\n"
     ]
    }
   ],
   "source": [
    "W, b = model.get_layer(index=0).get_weights()\n",
    "print(W, b)\n",
    "W, b = model.get_layer(index=1).get_weights()\n",
    "print(W, b)\n",
    "W, b = model.get_layer(index=2).get_weights()\n",
    "print(W, b)\n",
    "W, b = model.get_layer(index=3).get_weights()\n",
    "print(W, b)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
